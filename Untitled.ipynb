{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DSPy로 LLM을 프롬프팅이 아니라 프로그래밍하기 (Programming, not Prompting)\n",
    "\n",
    "**[DSPy(Declarative Self-improving Python)](https://dspy.ai/)** 는 스탠퍼드 NLP에서 개발한 프레임워크로, 언어 모델을 프롬프트 템플릿이 아니라 프로그래밍 가능한 함수로 다룬다. DSPy는 PyTorch와 유사한 인터페이스를 제공하여 LLM 연산을 정의하고, 조합하며, 최적화할 수 있게 한다.\n",
    "\n",
    "개발자는 복잡한 프롬프트를 직접 작성하고 유지하는 대신, **입·출력 시그니처만 선언**하면 되고, **프롬프트 엔지니어링과 최적화는 DSPy가 자동으로 처리**한다. 이 프레임워크는 자동 프롬프트 튜닝과 자기 개선(self-improvement)과 같은 기법을 통해 LLM 파이프라인을 체계적으로 개선할 수 있도록 한다.\n",
    "\n",
    "<img src=\"./Media/dspy_workflow.png\">\n",
    "\n",
    "DSPy의 워크플로우는 다음의 네 가지 핵심 단계로 구성된다:\n",
    "\n",
    "* 시그니처(Signature) 와 모듈(Module)을 사용해 프로그램을 정의한다.\n",
    "* 프로그램의 성능을 명확하게 보여줄 수 있는 측정 가능한 성공 지표를 설계한다.\n",
    "* 프로그램을 컴파일하고, 설정한 성공 지표를 기준으로 최적화한다.\n",
    "* 추가 데이터를 수집하고, 이를 바탕으로 반복적으로 개선한다.\n",
    "\n",
    "이 노트북에서는 이러한 단계 전반에 걸쳐 DSPy가 제공하는 다양한 접근 방식들을 살펴보고 실제로 적용해본다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "<img src=\"./Media/dspy.png\" width=\"200\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure LLM\n",
    "\n",
    "DSPy는 기본적으로 환경 전반에 걸쳐 모델과 응답을 캐시한다. 별도로 명시하지 않는 한, 한 번 언어 모델을 설정하면 이후의 모든 호출에서는 해당 언어 모델이 자동으로 사용된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "_ = load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = dspy.LM('openai/gpt-4o-mini')\n",
    "dspy.configure(lm=lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This is a test! How can I assist you further?']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm(messages=[{\"role\":\"user\", \"content\":\"Say this is a test!\"}])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 시그니처(Signatures)\n",
    "\n",
    "DSPy의 시그니처는 일반적인 함수 시그니처와 동일한 개념을 따르지만, 자연어로 정의된다는 점이 특징이다. 이는 DSPy가 대체하고자 하는 기존의 “프롬프팅(prompting)” 방식의 핵심에 해당한다. LLM에게 무엇을 하라고 지시하는 대신, LLM이 무엇을 하게 될지를 선언적으로 정의하는 접근을 취한다.\n",
    "\n",
    "기본 형식은 다음과 같다.\n",
    "\n",
    "'input -> output'\n",
    "\n",
    "입력과 출력은 원하는 어떤 형태든 정의할 수 있으며, 여러 개의 입력과 출력, 타입 정보, 혹은 더 명확하게 구조화된 스키마를 함께 선언하는 것도 가능하다.\n",
    "\n",
    "<img src=\"./Media/signatures.png\">\n",
    "\n",
    "내부적으로는 여전히 언어 모델을 위한 프롬프트가 사용되지만, 자연어로 정의한 시그니처를 기반으로 고정된 프롬프트가 아니라 모듈화된 형태로 동작한다. 즉, 시그니처에 따라 표현 방식과 구조가 동적으로 바뀌도록 설계되어 있다.\n",
    "\n",
    "프롬프팅을 추상화한다는 점에서 다소 직관에 어긋나게 느껴질 수 있지만, DSPy는 이러한 구조를 통해 모델을 쉽게 교체할 수 있고, 이후에 살펴볼 알고리즘 수준의 최적화도 가능하도록 설계되었다.\n",
    "\n",
    "### 단순한 입력과 출력(Simple Input & Output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response:  The sky appears blue because of a phenomenon called Rayleigh scattering. When sunlight enters the Earth's atmosphere, it collides with molecules and small particles in the air. Sunlight is made up of many colors, each having different wavelengths. Blue light waves are shorter and are scattered in all directions more than other colors with longer wavelengths, such as red and orange. This scattering causes us to see the sky as blue during the day.\n"
     ]
    }
   ],
   "source": [
    "qna = dspy.Predict('question -> answer')\n",
    "response = qna(question=\"Why is the sky blue\")\n",
    "print(\"Response: \", response.answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34m[2026-01-14T15:15:26.928240]\u001b[0m\n",
      "\n",
      "\u001b[31mSystem message:\u001b[0m\n",
      "\n",
      "Your input fields are:\n",
      "1. `question` (str):\n",
      "Your output fields are:\n",
      "1. `answer` (str):\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## question ## ]]\n",
      "{question}\n",
      "\n",
      "[[ ## answer ## ]]\n",
      "{answer}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "In adhering to this structure, your objective is: \n",
      "        Given the fields `question`, produce the fields `answer`.\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## question ## ]]\n",
      "Why is the sky blue\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## answer ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001b[31mResponse:\u001b[0m\n",
      "\n",
      "\u001b[32m[[ ## answer ## ]]\n",
      "The sky appears blue because of a phenomenon called Rayleigh scattering. When sunlight enters the Earth's atmosphere, it collides with molecules and small particles in the air. Sunlight is made up of many colors, each having different wavelengths. Blue light waves are shorter and are scattered in all directions more than other colors with longer wavelengths, such as red and orange. This scattering causes us to see the sky as blue during the day. \n",
      "\n",
      "[[ ## completed ## ]]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lm.inspect_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:  The market for our products is highly competitive and influenced by rapid technological advancements and changing industry standards. Key competitive factors include product performance, range, customer access, and distribution channels. Our competitiveness hinges on our ability to predict customer demands, deliver quality products consistently, and maintain competitive pricing. We anticipate increased competition from both current players and new entrants offering lower prices or superior features, as well as potential alliances among competitors. Significant competition arises from companies focused on GPUs, CPUs, DPUs, and other advanced computing products. Some rivals may possess greater resources, making it challenging to keep pace with market changes. The competitive landscape is expected to become more intense in the future.\n"
     ]
    }
   ],
   "source": [
    "sum = dspy.Predict('document -> summary')\n",
    "\n",
    "document = \"\"\"\n",
    "The market for our products is intensely competitive and is characterized by rapid technological change and evolving industry standards. \n",
    "We believe that theprincipal competitive factors in this market are performance, breadth of product offerings, access to customers and partners and distribution channels, softwaresupport, conformity to industry standard APIs, manufacturing capabilities, processor pricing, and total system costs. \n",
    "We believe that our ability to remain competitive will depend on how well we are able to anticipate the features and functions that customers and partners will demand and whether we are able todeliver consistent volumes of our products at acceptable levels of quality and at competitive prices. \n",
    "We expect competition to increase from both existing competitors and new market entrants with products that may be lower priced than ours or may provide better performance or additional features not provided by our products. \n",
    "In addition, it is possible that new competitors or alliances among competitors could emerge and acquire significant market share.\n",
    "A significant source of competition comes from companies that provide or intend to provide GPUs, CPUs, DPUs, embedded SoCs, and other accelerated, AI computing processor products, and providers of semiconductor-based high-performance interconnect products based on InfiniBand, Ethernet, Fibre Channel,and proprietary technologies. \n",
    "Some of our competitors may have greater marketing, financial, distribution and manufacturing resources than we do and may bemore able to adapt to customers or technological changes. \n",
    "We expect an increasingly competitive environment in the future.\n",
    "\"\"\"\n",
    "\n",
    "response = sum(document=document)\n",
    "print(\"Summary: \", response.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Inputs and Outputs\n",
    "\n",
    "<img src='./Media/multiple_signature.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:  Your name is Adam Lucek.\n",
      "\n",
      "Citation:  The user identified as Adam Lucek in the context provided.\n"
     ]
    }
   ],
   "source": [
    "multi = dspy.Predict('question, context -> answer, citation')\n",
    "\n",
    "question = \"What's my name?\"\n",
    "context = \"The user you're talking to is Adam Lucek, AI youtuber extraordinare\"\n",
    "\n",
    "response = multi(question=question, context=context)\n",
    "\n",
    "print(\"Answer: \", response.answer)\n",
    "print(\"\\nCitation: \", response.citation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Type Hints with Outputs\n",
    "\n",
    "<img src=\"./Media/input_type.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment Classification:  negative\n",
      "\n",
      "Confidence:  0.85\n",
      "\n",
      "Reasoning:  The phrase \"I didn't really like it\" clearly expresses dissatisfaction or discontent, indicating a negative sentiment. The use of \"didn't really like\" suggests a strong sense of disapproval, thus reinforcing the negative sentiment. The confidence level is high due to the clarity of the expression.\n"
     ]
    }
   ],
   "source": [
    "emotion = dspy.Predict('input -> sentiment: str, confidence: float, reasoning: str')\n",
    "\n",
    "text = \"I don't quite know, I didn't really like it\"\n",
    "\n",
    "response = emotion(input=text)\n",
    "\n",
    "print(\"Sentiment Classification: \", response.sentiment)\n",
    "print(\"\\nConfidence: \", response.confidence)\n",
    "print(\"\\nReasoning: \", response.reasoning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 클래스 기반 시그니처(Class-Based Signatures)\n",
    "\n",
    "보다 고급 시그니처를 위해, DSPy는 단순한 인라인 문자열 방식 대신 Pydantic 클래스 또는 데이터 구조 스키마를 정의할 수 있도록 지원한다. 이러한 클래스는 기본적으로 dspy.Signature를 상속받아야 하며, 입력 필드는 dspy.InputField(), 출력 필드는 dspy.OutputField()를 사용해 명시적으로 정의해야 한다.\n",
    "\n",
    "각 필드에는 선택적으로 desc 인자를 전달할 수 있으며, 이를 통해 해당 필드에 대한 추가적인 맥락이나 설명을 함께 제공할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed Text:  In the haven of fragrant brews, a sanctuary for souls to meet,  \n",
      "The coffee shop whispers secrets of lattes, a delightful treat.  \n",
      "A bard behind the counter, with skilled hands and a knowing heart,  \n",
      "Crafts magic with the espresso machine, a true work of art.\n",
      "\n",
      "Style Metrics:  {'formality': 0.6, 'complexity': 0.75, 'emotiveness': 0.8}\n",
      "\n",
      "Preserver Keywords:  ['coffee shop', 'lattes', 'barista', 'espresso machine']\n"
     ]
    }
   ],
   "source": [
    "from typing import Literal\n",
    "\n",
    "class TextStyleTransfer(dspy.Signature):\n",
    "    \"\"\"Transfer text between different writing styles while preserving content.\"\"\"\n",
    "    text: str = dspy.InputField()\n",
    "    source_style: Literal[\"academic\", \"casual\", \"business\", \"poetic\"] = dspy.InputField()\n",
    "    target_style: Literal[\"academic\", \"casual\", \"business\", \"poetic\"] = dspy.InputField()\n",
    "    preserved_keywords: list[str] = dspy.OutputField()\n",
    "    transformed_text: str = dspy.OutputField()\n",
    "    style_metrics: dict[str, float] = dspy.OutputField(desc=\"Scores for formality, complexity, emotiveness\")\n",
    "\n",
    "text = \"This coffee shop makes the best lattes ever! Their new barista really knows what he's doing with the espresso machine.\"\n",
    "\n",
    "style_transfer = dspy.Predict(TextStyleTransfer)\n",
    "\n",
    "response = style_transfer(\n",
    "    text=text,\n",
    "    source_style=\"casual\",\n",
    "    target_style=\"poetic\"\n",
    ")\n",
    "\n",
    "print(\"Transformed Text: \", response.transformed_text)\n",
    "print(\"\\nStyle Metrics: \", response.style_metrics)\n",
    "print(\"\\nPreserver Keywords: \", response.preserved_keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모듈(Modules)\n",
    "\n",
    "<img src=\"./Media/modules.png\">\n",
    "\n",
    "모듈은 시그니처에 다양한 프롬프팅 전략을 적용하는 계층이다. 앞선 시그니처 예제에서는 기본적인 Predict 모듈을 사용했지만, DSPy에는 이 외에도 널리 사용되는 여러 전략과 그 변형들이 준비되어 있다. 다음은 현재 제공되는 주요 모듈들이다.\n",
    "\n",
    "* **ChainOfThought**: 출력을 생성하기 전에 추론 단계를 먼저 유도하는 체인-오브-쏘트(chain-of-thought) 프롬프팅을 구현한다. 이 모듈은 모델이 구조화된 사고를 하도록 \"Let's think step by step\"과 같은 문구를 자동으로 추가한다. 복잡한 문제를 여러 단계로 나누어 사고해야 하는 경우에 적합하다.\n",
    "  \n",
    "* **ProgramOfThought**: 문제 해결을 위해 실행 가능한 Python 코드를 생성하며, 오류 처리와 코드 재생성 기능을 기본적으로 포함한다. 수학적 문제나 알고리즘적 문제처럼 실제 코드 실행을 통해 해결하는 것이 더 효과적인 경우에 사용한다.\n",
    "\n",
    "* **ReAct**: 사고(Reasoning), 행동(Acting: 도구 사용), 관찰(Observation)을 구조화된 루프 형태로 번갈아 수행하는 ReAct 방식을 구현한다.여러 단계의 추론과 외부 도구나 API와의 상호작용이 필요한 작업에 적합하다.\n",
    "\n",
    "그리고 몇 가지 헬퍼 모듈:\n",
    "\n",
    "* **MultiChainComparison**: 여러 번의 추론 시도(기본값 3회)를 수행한 뒤, 서로 다른 추론 경로를 비교하여 더 정확한 하나의 응답으로 통합한다. 문제 해결의 정확도가 중요하고, 여러 번의 시도를 감당할 수 있는 경우에 적합하다.\n",
    "\n",
    "* **Majority**: 여러 개의 응답(completion)을 입력으로 받아 텍스트를 정규화한 뒤, 가장 많이 등장한 응답을 반환하는 유틸리티 함수다. 여러 번의 생성 결과에 대해 간단한 투표 방식을 적용해 신뢰도를 높이고 싶을 때 유용하다.\n",
    "\n",
    "### Chain of Thought\n",
    "\n",
    "<img src=\"./Media/cot_module.png\" width=\"300\">\n",
    "\n",
    "**ChainOfThought**는 출력 전에 명시적인 추론 단계를 포함하도록 프롬프트 시그니처를 수정하는 방식으로 동작한다. 시그니처로 초기화되면, \"Reasoning: Let's think step by step in order to\"라는 접두어를 가진 reasoning 필드를 앞에 추가한 확장 시그니처를 생성한다. 이 reasoning 필드는 언어 모델이 최종 답변을 제공하기에 앞서 사고 과정을 먼저 작성하도록 강제한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment:  mixed\n",
      "\n",
      "Reasoning:  The phrase \"That was phenomenal\" suggests a positive experience or appreciation, indicating enjoyment or admiration. However, the phrase \"but I hated it!\" introduces a strong negative sentiment that contradicts the previous positive remark. This juxtaposition indicates a mixed sentiment where the speaker acknowledges something remarkable but also expresses strong dislike, possibly due to personal reasons or conflicting feelings about the experience.\n"
     ]
    }
   ],
   "source": [
    "# Define the Signature and Module\n",
    "cot_emotion = dspy.ChainOfThought('input -> sentiment: str')\n",
    "\n",
    "# Example\n",
    "text = \"That was phenomenal, but I hated it!\"\n",
    "\n",
    "# Run\n",
    "cot_response = cot_emotion(input=text)\n",
    "\n",
    "# Output\n",
    "print(\"Sentiment: \", cot_response.sentiment)\n",
    "# Inherently added reasoning\n",
    "print(\"\\nReasoning: \", cot_response.reasoning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Program of Thought\n",
    "\n",
    "<img src=\"./Media/program_of_thought.png\">\n",
    "\n",
    "ProgramOfThought(PoT)는 자연어 출력에 직접 의존하는 대신, 실행 가능한 Python 코드를 생성하여 과제를 해결한다. 작업이 주어지면, PoT는 먼저 ChainOfThought 예측기를 사용해 Python 코드를 생성한 뒤, 이를 격리된 Python 인터프리터 환경에서 실행한다. 코드 실행 중 오류가 발생하면, PoT는 해당 오류를 언어 모델에 다시 전달하고 수정된 코드를 생성하도록 요청하는 개선 루프에 들어간다. 이 과정은 최대 지정된 반복 횟수(기본값 3회)까지 반복된다. 최종 출력은 언어 모델이 직접 생성한 텍스트가 아니라, 성공적으로 실행된 코드의 실제 실행 결과에서 얻어진다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Signature\n",
    "class MathAnalysis(dspy.Signature):\n",
    "    \"\"\"Analyze a dataset and compute various statistical metrics.\"\"\"\n",
    "    numbers: list[float] = dspy.InputField(desc=\"List of numerical values to analyze\")\n",
    "    required_metrics: list[str] = dspy.InputField(desc=\"List of metrics to calculate (e.g. ['mean', variance', 'quartiles'])\")\n",
    "    analysis_results: dict[str, float] = dspy.OutputField(desc=\"Dictionary containing the calculated metrics\")\n",
    "\n",
    "# Create the module\n",
    "math_analyzer = dspy.ProgramOfThought(MathAnalysis)\n",
    "\n",
    "# Example\n",
    "data = [1.5, 2.8, 3.2, 4.7, 5.1, 2.3, 3.9]\n",
    "metrics = ['mean', 'median']\n",
    "\n",
    "# Run\n",
    "pot_response = math_analyzer(\n",
    "    numbers=data,\n",
    "    required_metrics=metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reasoning:  The code provided calculates the mean and median of the given list of numbers using NumPy functions. The mean is the average of the numbers, while the median is the middle value when the numbers are sorted. The results were expected based on standard calculations for these statistics.\n",
      "\n",
      "Results:  {'mean': 3.2857142857142856, 'median': 3.2}\n"
     ]
    }
   ],
   "source": [
    "print(\"Reasoning: \", pot_response.reasoning)\n",
    "print(\"\\nResults: \", pot_response.analysis_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reasoning + Acting (ReAct)\n",
    "\n",
    "<img src=\"./Media/react.png\">\n",
    "\n",
    "ReAct는 **추론(reasoning)** 과 **도구 사용(tool usage)** 을 결합하여 상호작용적인 문제 해결을 가능하게 한다. 이는 모델이 **생각–행동(thought–action) 쌍의 흐름(trajectory)** 을 유지하면서 작동하는 방식으로, 각 단계마다 모델은 자신의 추론을 설명하고, 사용할 도구를 선택하며, 해당 도구에 전달할 인자를 제공한 뒤, 도구 실행 결과를 관찰하여 다음 단계를 결정한다. 각 반복(iteration)은 네 가지 요소로 구성된다. 즉, 전략을 설명하는 **생각(thought)**, 사용 가능한 도구 중 하나를 선택하는 **도구 선택**, 도구에 전달할 **인자(arguments)**, 그리고 도구를 실행한 결과인 **관찰(observation)** 이다. 이 과정은 모델이 스스로 “finish”를 선택하거나 최대 반복 횟수에 도달할 때까지 계속된다. 아래는 간단한 예시이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:  The Baltimore Orioles won the World Series in 1983, and England won the World Cup in 1966.\n",
      "\n",
      "Reasoning:  The Baltimore Orioles won the World Series in 1983, and the England national team won the World Cup in 1966. This information is widely recognized in sports history and can be confirmed through reliable sources, despite the technical issues encountered while attempting to retrieve it.\n"
     ]
    }
   ],
   "source": [
    "# Define a Tool\n",
    "def wikipedia_search(query: str) -> list[str]:\n",
    "    \"\"\"Retrieves abstracts from Wikipedia.\"\"\"\n",
    "    # Existing Wikipedia Abstracts Server\n",
    "    results = dspy.ConBERTv2(url='http://20.102.90.50:2017/wiki17_abstracts')(query, k=3)\n",
    "    return [x['text'] for x in results]\n",
    "\n",
    "# Define ReAct Module\n",
    "react_module = dspy.ReAct('question -> response', tools=[wikipedia_search])\n",
    "\n",
    "# Example\n",
    "text = \"Who won the world series in 1983 and who won the world cup in 1966?\"\n",
    "\n",
    "# Run\n",
    "react_response = react_module(question=text)\n",
    "\n",
    "print(\"Answer: \", react_response.response)\n",
    "print(\"\\nReasoning: \", react_response.reasoning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Chain Comparison\n",
    "\n",
    "<img src=\"./Media/multi_chain.png\">\n",
    "\n",
    "MultiChainComparison은 여러 개의 기존 응답(completion)을 하나의 더 견고한 최종 예측으로 종합하는 **메타 예측기(meta-predictor)** 이다. 이 모듈은 스스로 예측을 생성하지 않고, 대신 다른 예측기들로부터 **M개의 서로 다른 응답(기본값 3)** 을 입력으로 받는다. 이 응답들은 동일한 예측기를 서로 다른 temperature로 실행한 결과일 수도 있고, 완전히 다른 예측기에서 나온 결과일 수도 있으며, 혹은 동일한 설정으로 여러 번 호출한 결과일 수도 있다.\n",
    "\n",
    "각 응답은 Student Attempt #1:, Student Attempt #2: 와 같은 형식으로 정리되며,\n",
    "각 시도는 «나는 [추론 과정]을 바탕으로 생각해 보았고, 확신은 없지만 내 예측은 [답]이다»\n",
    "와 같은 구조로 패키징된다.\n",
    "이후 모듈은 “Accurate Reasoning: Thank you everyone. Let’s now holistically…”와 같은 프롬프트를 사용해, 모델이 이 여러 시도를 종합적으로 분석·비교·비판하도록 유도하고, 그 결과로 하나의 최종 답변을 도출한다.\n",
    "\n",
    "이 접근법은 모델이 최종 결정을 내리기 전에 여러 해결 경로를 명시적으로 비교하고 검토하게 함으로써, 개별 예측에서 발생할 수 있는 오류를 완화하는 데 도움을 준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment: Positive\n",
      "\n",
      "Reasoning: The word \"piculous\" conveys a sense of something being unusual or strange, and the exclamation mark implies an emotional reaction from the speaker. This suggests a mixture of surprise and intrigue. Therefore, the sentiment can be categorized as Positive, as the speaker seems to express an emotional response to an unexpected situation.\n",
      "\n",
      "Completion 1:  Prediction(\n",
      "    reasoning='The word \"piciular\" suggests that something was unusual or strange, which can indicate a sense of confusion or surprise. The exclamation mark emphasizes the speaker\\'s emotional reaction, indicating that they found the experience noteworthy or unexpected.',\n",
      "    sentiment='Surprised'\n",
      ")\n",
      "\n",
      "Completion 2:  Prediction(\n",
      "    reasoning='The word \"piculair\" suggests that something was unusual or strange, potentially implying a sense of confusion or curiosity. The use of punctuation indicates a strong reaction, which could indicate surprise or intrigue.',\n",
      "    sentiment='Neutral with a hint of curiosity.'\n",
      ")\n",
      "\n",
      "Completion 3:  Prediction(\n",
      "    reasoning='The word \"puculiar\" suggests something unusual or strange. The use of an exclamation mark indicates that the speaker found the experience or situation noteworthy. Overall, this conveys a sense of surprise or intrigue regarding what was observed.',\n",
      "    sentiment='Neutral / Positive'\n",
      ")\n",
      "\n",
      "Completion 4:  Prediction(\n",
      "    reasoning='The word \"picular\" seems to be a typographical error or may imply something strange or odd. The context does not provide a clear emotional tone, but it suggests a sense of curiosity or mild confusion about the situation described.',\n",
      "    sentiment='Neutral'\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Run CoT completions with increasing temperatures\n",
    "text = \"That was piculiar!\"   # strange, piculiar, exotic, phenominal\n",
    "\n",
    "cot_completions = []\n",
    "for i in range(4):\n",
    "    # Temperature increases: 0.7, 0.8, 0.9\n",
    "    temp_config = dict(temperature=0.7+(0.1*i))\n",
    "    completion = cot_emotion(input=text, config=temp_config)\n",
    "    cot_completions.append(completion)\n",
    "\n",
    "# Synthesize with MultiChainComparison\n",
    "mcot_emotion = dspy.MultiChainComparison('input -> sentiment', M=4)\n",
    "final_result = mcot_emotion(completions=cot_completions, input=text)\n",
    "\n",
    "print(f\"Sentiment: {final_result.sentiment}\")\n",
    "print(f\"\\nReasoning: {final_result.rationale}\")\n",
    "\n",
    "for i in range(4):\n",
    "    print(f\"\\nCompletion {i+1}: \", cot_completions[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Majority\n",
    "\n",
    "<img src=\"./Media/majority.png\">\n",
    "\n",
    "Majority는 여러 개의 응답(completion)을 대상으로 기본적인 투표 메커니즘을 적용해 가장 많이 등장한 답을 선택하는 유틸리티 함수다. 이 함수는 응답들을 포함한 Prediction 객체를 입력으로 받거나, 혹은 응답 리스트 자체를 직접 입력으로 받을 수 있다. 동작 과정에서 Majority는 대상 필드의 값을 정규화(normalization)하는데, 이때 사용할 필드는 명시적으로 지정할 수도 있고, 지정하지 않으면 기본적으로 마지막 출력 필드가 사용된다. 이 정규화 과정은 normalize_text 함수가 담당하며, 의미적으로 동일하지만 표현이 약간 다른 텍스트들을 같은 답으로 취급하도록 돕는다. 또한 무시되어야 할 답변의 경우 None을 반환하도록 처리한다. 표 수가 같은 경우(동률)에는 먼저 생성된 응답이 우선된다. 이 함수는 서로 다른 temperature로 예측기를 여러 번 실행하는 등, 다수의 응답을 생성하는 모듈들과 함께 사용할 때 특히 유용하며, 가장 일반적인 답을 간단히 선택할 수 있는 방법을 제공한다. 최종적으로 Majority는 선택된(승리한) 하나의 응답만을 포함하는 새로운 Prediction 객체를 반환한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common sentiment: Surprised\n"
     ]
    }
   ],
   "source": [
    "# Example Completions From Prior Multi-Chain\n",
    "majority_result = dspy.majority(cot_completions, field=\"sentiment\")\n",
    "\n",
    "# Results\n",
    "print(f\"Most common sentiment: {majority_result.sentiment}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
